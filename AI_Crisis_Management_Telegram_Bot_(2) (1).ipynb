{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c30ee739",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c30ee739",
        "outputId": "4cf43fb0-cdaa-4aff-ccb0-40f804128f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.2.14 in /usr/local/lib/python3.11/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain-nvidia-ai-endpoints==0.2.1 in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain-community==0.2.12 in /usr/local/lib/python3.11/dist-packages (0.2.12)\n",
            "Requirement already satisfied: langchain-core==0.2.33 in /usr/local/lib/python3.11/dist-packages (0.2.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (3.11.15)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (2.11.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14) (8.5.0)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from langchain-nvidia-ai-endpoints==0.2.1) (10.4.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.12) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.33) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.33) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.33) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.33) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.14) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.14) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.14) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.14) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.14) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.14) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (1.3.1)\n",
            "Requirement already satisfied: faiss-cpu==1.8.0 in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
            "Requirement already satisfied: PyMuPDF==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.3 in /usr/local/lib/python3.11/dist-packages (from PyMuPDF==1.24.4) (1.24.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot --quiet\n",
        "!pip install langchain==0.2.14 langchain-nvidia-ai-endpoints==0.2.1 langchain-community==0.2.12 langchain-core==0.2.33\n",
        "!pip install faiss-cpu==1.8.0 #Facebook AI Similarity Search\n",
        "!pip install PyMuPDF==1.24.4 #for PDF parsing and content extraction\n",
        "!pip install beautifulsoup4 #to extract data from web pages or documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b474ca",
      "metadata": {
        "id": "86b474ca"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import logging\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes, ConversationHandler\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
        "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
        "    assert nvapi_key.startswith(\"nvapi-\"), \"Invalid NVIDIA API key.\"\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n",
        "#Key:  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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdr2w_K1Ol-Q",
        "outputId": "708987a6-4ddd-4487-cd4d-90bdf17d1edb"
      },
      "id": "bdr2w_K1Ol-Q",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your NVIDIA API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7084d1e",
      "metadata": {
        "id": "c7084d1e"
      },
      "outputs": [],
      "source": [
        "def html_document_loader(url): #prepares web content for downstream NLP tasks, such as vector embedding.\n",
        "    try:\n",
        "        response = requests.get(url) # Send GET request to fetch web page content\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\") # Parse HTML content using BeautifulSoup\n",
        "        for tag in soup([\"script\", \"style\"]): tag.decompose()\n",
        "        return re.sub(\"\\s+\", \" \", soup.get_text()).strip() # Extract, normalize, and clean up the visible text content\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def create_embeddings(embedding_path=\"./data/crisis_embedding\"): #reusable pipeline to build & update a local semantic search database from a list of URLs.\n",
        "    urls = [\n",
        "        \"https://petra.gov.jo/Include/Main.jsp?lang=en\",\n",
        "        \"https://www.aljazeera.com/\",\n",
        "        \"https://jordan.gov.jo/EN/ListDetails/Government_Entities/55/6\",\n",
        "        \"https://www.ncscm.gov.jo/EN/Pages/Blocking_Water_and_Floods\",\n",
        "        \"https://www.ncscm.gov.jo/EN/Pages/Earthquakes\",\n",
        "        \"https://www.ncscm.gov.jo/EN/Pages/Snowfall\",\n",
        "        \"https://www.jordannews.jo/Section-109/News/Crisis-Management-Center-launches-drill-Sunday-27483\",\n",
        "        \"https://www.ncscm.gov.jo/EN/Pages/Contact_Us\",\n",
        "        \"https://www.icrc.org/en\",\n",
        "        \"https://jordantimes.com/\",\n",
        "        \"https://www.jnrcs.org/ar/latestnews\",\n",
        "        \"https://www.thepersonal.com/blog/-/what-to-do-in-case-of-a-natural-disaster\",\n",
        "        \"https://www.getprepared.gc.ca/cnt/kts/index-en.aspx\"\n",
        "\n",
        "    ]\n",
        "    documents = [html_document_loader(url) for url in urls]\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    texts = text_splitter.create_documents(documents)\n",
        "    embeddings = NVIDIAEmbeddings(model=\"NV-Embed-QA\", truncate=\"END\") # Initialize NVIDIA embedding model for text chunk vectorization\n",
        "\n",
        "    if os.path.exists(embedding_path):\n",
        "        vectorstore = FAISS.load_local(folder_path=embedding_path, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
        "        vectorstore.add_documents(texts)\n",
        "    else:\n",
        "        vectorstore = FAISS.from_documents(texts, embedding=embeddings)\n",
        "\n",
        "    vectorstore.save_local(folder_path=embedding_path)\n",
        "    return vectorstore\n",
        "\n",
        "embedding_path = \"./data/crisis_embedding\" #path where the FAISS vectorstore is stored\n",
        "if not os.path.exists(embedding_path):\n",
        "    create_embeddings(embedding_path)\n",
        "\n",
        "embedding_model = NVIDIAEmbeddings(model=\"NV-Embed-QA\", truncate=\"END\")\n",
        "docsearch = FAISS.load_local(folder_path=embedding_path, embeddings=embedding_model, allow_dangerous_deserialization=True) # entry point for retrieval operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18af3bca",
      "metadata": {
        "id": "18af3bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4524b20-f6a2-4e83-8c79-7075619add13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use create_history_aware_retriever together with create_retrieval_chain (see example in docstring) instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "llm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\") # Initialize the LLaMA 3 model for question rephrazing\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True) # memory buffer to maintain chat history (context-aware conversations)\n",
        "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT) # Create a chain to rephrases follow-up questions.\n",
        "chat = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", temperature=0.1, max_tokens=1000, top_p=1.0) #mistral nvidia model Answering questions using retrieved documents\n",
        "doc_chain = load_qa_chain(chat, chain_type=\"stuff\", prompt=QA_PROMPT) # Create a QA chain to answer questions using retrieved documents and nvidia model.\n",
        "qa = ConversationalRetrievalChain(\n",
        "    retriever=docsearch.as_retriever(),\n",
        "    combine_docs_chain=doc_chain,\n",
        "    memory=memory,\n",
        "    question_generator=question_generator,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8RsmAcBpB7CN"
      },
      "id": "8RsmAcBpB7CN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8a3962",
      "metadata": {
        "id": "bf8a3962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceaf8624-6e2b-4f03-bc71-a5b5cd4c17eb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot started. Send /start to your bot.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "ASK_TYPE, ASK_LOCATION, CHAT = range(3) # Define conversation states for crisis type, location, and Q&A\n",
        "user_context = {} # Store each user data .\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"💬Welcome! What type of crisis are you facing?\")\n",
        "    return ASK_TYPE\n",
        "\n",
        "# Save user's crisis type and prompt for location\n",
        "async def ask_location(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_context[update.effective_chat.id] = {\"crisis\": update.message.text}\n",
        "    await update.message.reply_text(\"📌Please share your location (city/area)?\")\n",
        "    return ASK_LOCATION\n",
        "\n",
        "# Run RAG model on crisis + location input and share response; then ask for follow-up\n",
        "async def provide_advice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_id = update.effective_chat.id\n",
        "    user_context[user_id][\"location\"] = update.message.text\n",
        "    crisis_info = f\"Crisis: {user_context[user_id]['crisis']} in {user_context[user_id]['location']}\"\n",
        "    response = qa.run(crisis_info)\n",
        "    await update.message.reply_text(response)\n",
        "    await update.message.reply_text(\"Do you have more questions about this crisis?\")\n",
        "    return CHAT\n",
        "\n",
        "# Handle general follow-up questions or end conversation if user sends /stop\n",
        "async def continue_conversation(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    if update.message.text.strip().lower() == \"/stop\":\n",
        "        await update.message.reply_text(\"Stay safe. Ending conversation.\")\n",
        "        return ConversationHandler.END\n",
        "    response = qa.run(update.message.text)\n",
        "    await update.message.reply_text(response)\n",
        "    return CHAT\n",
        "\n",
        "async def stop(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"Conversation stopped. Stay safe!\")\n",
        "    return ConversationHandler.END\n",
        "\n",
        "app = ApplicationBuilder().token(\"8037648144:AAGgsMLgV_zPU7iEY1e1MxdnWQJ6g21B_Yw\").build() # Initialize Telegram bot with provided token\n",
        "\n",
        "# Define conversation flow for start, collecting info, and chatting with QA model\n",
        "handler = ConversationHandler(\n",
        "    entry_points=[CommandHandler(\"start\", start)],\n",
        "    states={\n",
        "        ASK_TYPE: [MessageHandler(filters.TEXT & ~filters.COMMAND, ask_location)],\n",
        "        ASK_LOCATION: [MessageHandler(filters.TEXT & ~filters.COMMAND, provide_advice)],\n",
        "        CHAT: [MessageHandler(filters.TEXT & ~filters.COMMAND, continue_conversation)],\n",
        "    },\n",
        "    fallbacks=[CommandHandler(\"stop\", stop)],\n",
        ")\n",
        "\n",
        "app.add_handler(handler)\n",
        "\n",
        "\n",
        "# Async function to start and keep the bot running inside Colab\n",
        "async def run_bot():\n",
        "    await app.initialize()\n",
        "    await app.start()\n",
        "    print(\"Bot started. Send /start to your bot.\")\n",
        "    await app.updater.start_polling()\n",
        "    # Keep it running forever unless stopped manually\n",
        "    await asyncio.Event().wait()\n",
        "\n",
        "# Start the bot in the background event loop\n",
        "await run_bot()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}